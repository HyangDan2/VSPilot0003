
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from webdriver_manager.chrome import ChromeDriverManager
import logging
import time

class NewsCrawler:
    """
    Selenium ê¸°ë°˜ ë„¤ì´ë²„ ë‰´ìŠ¤ 'ë‹¨ë…' ê¸°ì‚¬ í¬ë¡¤ëŸ¬ (JS ë Œë”ë§ ëŒ€ì‘ + ë‰´ìŠ¤ íƒ­ í´ë¦­ + ë””ë²„ê¹… ì €ì¥)
    """
    def __init__(self):
        self.sent_links = set()
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--window-size=1920x1080")
        self.driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()),
            options=options
        )

    def crawl(self, search_query="ë‹¨ë…"):
        url = f"https://search.naver.com/search.naver?where=news&query={search_query}"
        self.driver.get(url)
        time.sleep(2)

        # ë‰´ìŠ¤ íƒ­ í´ë¦­ ë¨¼ì € ì‹œë„
        try:
            news_tab = WebDriverWait(self.driver, 5).until(
                EC.element_to_be_clickable((By.LINK_TEXT, "ë‰´ìŠ¤"))
            )
            news_tab.click()
            time.sleep(2)
        except Exception as e:
            self.logger.warning(f"ë‰´ìŠ¤ íƒ­ í´ë¦­ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {e}")

        # ë Œë”ë§ëœ í˜ì´ì§€ ì €ì¥ (íƒ­ í´ë¦­ í›„)
        with open("debug_page.html", "w", encoding="utf-8") as f:
            f.write(self.driver.page_source)

        soup = BeautifulSoup(self.driver.page_source, "html.parser")
        news_items = soup.select("a.news_title")
        self.logger.info(f"ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜: {len(news_items)}ê°œ")

        found_articles = []
        for tag in news_items:
            title = tag.get_text(strip=True)
            link = tag.get("href")
            if not title or not link:
                continue
            if "ë‹¨ë…" not in title and "íŠ¹ë³„ì·¨ì¬" not in title:
                continue
            if link in self.sent_links:
                continue
            found_articles.append({"title": title, "link": link})
            self.sent_links.add(link)
            self.logger.info(f"[ë‹¨ë…] {title} - {link}")
            if len(found_articles) >= 10:
                break

        return found_articles

if __name__ == "__main__":
    crawler = NewsCrawler()
    articles = crawler.crawl()

    print("ğŸ” debug_page.html ì €ì¥ ì™„ë£Œ!")
    print("ğŸ“„ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡:")

    if not articles:
        print("âŒ ë‹¨ë…/íŠ¹ë³„ì·¨ì¬ ê¸°ì‚¬ ì—†ìŒ!")
    else:
        for i, a in enumerate(articles, start=1):
            print(f"{i}. {a['title']}")
            print(f"   â†³ {a['link']}")